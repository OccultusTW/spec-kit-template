---
description: "BOA æ‰¹æ¬¡è½‰æª”æœå‹™å¯¦ä½œä»»å‹™æ¸…å–®"
---

# ä»»å‹™ï¼šBOA æ‰¹æ¬¡è½‰æª”æœå‹™

**è¼¸å…¥**ï¼šä¾†è‡ª `/specs/001-boa-bch-transformat/` çš„è¨­è¨ˆæ–‡ä»¶
**å…ˆæ±ºæ¢ä»¶**ï¼šplan.mdï¼ˆå¿…éœ€ï¼‰ã€spec.mdï¼ˆä½¿ç”¨è€…æ•…äº‹å¿…éœ€ï¼‰ã€research.mdã€data-model.mdã€contracts/

**çµ„ç¹”åŸå‰‡**ï¼šä»»å‹™æŒ‰ä½¿ç”¨è€…æ•…äº‹åˆ†çµ„ï¼Œç¢ºä¿æ¯å€‹æ•…äº‹å¯ç¨ç«‹å¯¦ä½œå’Œæ¸¬è©¦
**ä»»å‹™å¤§å°**ï¼šæ¯å€‹ä»»å‹™éƒ½è¶³å¤ å°ï¼Œå¯åœ¨ 30 åˆ†é˜å…§å®Œæˆä¸¦ç«‹å³é©—è­‰çµæœ

## æ ¼å¼ï¼š`- [ ] [ID] [P?] [Story] æè¿°`

- **[P]**ï¼šå¯ä¸¦è¡ŒåŸ·è¡Œï¼ˆä¸åŒæª”æ¡ˆã€ç„¡ä¾è³´ï¼‰
- **[Story]**ï¼šæ‰€å±¬ä½¿ç”¨è€…æ•…äº‹ï¼ˆUS1ã€US2ã€US3ã€US4ï¼‰
- **è·¯å¾‘**ï¼šæ‰€æœ‰è·¯å¾‘ä½¿ç”¨çµ•å°è·¯å¾‘æ ¼å¼

## è·¯å¾‘æ…£ä¾‹

- å°ˆæ¡ˆæ ¹ç›®éŒ„ï¼š`boa-bch-transformat/`
- åŸå§‹ç¢¼ï¼š`src/transformat/`
- æ¸¬è©¦ï¼š`tests/`
- é…ç½®ï¼š`src/transformat/config/`

---

## éšæ®µ 1ï¼šè¨­å®šï¼ˆå…±äº«åŸºç¤è¨­æ–½ï¼‰

**ç›®çš„**ï¼šå°ˆæ¡ˆåˆå§‹åŒ–å’ŒåŸºæœ¬çµæ§‹

- [X] T001 å»ºç«‹å°ˆæ¡ˆç›®éŒ„çµæ§‹ï¼ˆä¾ç…§ plan.md Â§å°ˆæ¡ˆçµæ§‹ï¼‰
- [X] T002 åˆå§‹åŒ– Python 3.13 è™›æ“¬ç’°å¢ƒï¼ˆ.venvï¼‰
- [X] T003 [P] å»ºç«‹ requirements.txtï¼ˆpyarrow, psycopg2, paramiko, requests, loguru, wcwidth, tenacityï¼‰
- [X] T004 [P] é…ç½®ç’°å¢ƒæª”æ¡ˆï¼ˆresources/env/local.env, ut.env, uat.env, prod.envï¼‰
- [X] T005 [P] å»ºç«‹ .gitignoreï¼ˆæ’é™¤ .venv, *.pyc, __pycache__, .envï¼‰

**æª¢æŸ¥é»**ï¼šåŸ·è¡Œ `python --version` ç¢ºèª 3.13ï¼ŒåŸ·è¡Œ `pip list` ç¢ºèªæ‰€æœ‰ä¾è³´å®‰è£æˆåŠŸ

---

## éšæ®µ 2ï¼šåŸºç¤è¨­æ–½ï¼ˆé˜»å¡æ€§å‰ç½®æ¢ä»¶ï¼‰

**ç›®çš„**ï¼šæ‰€æœ‰ä½¿ç”¨è€…æ•…äº‹å…±ç”¨çš„æ ¸å¿ƒåŸºç¤è¨­æ–½

**âš ï¸ é—œéµ**ï¼šæ­¤éšæ®µå¿…é ˆå®Œæˆæ‰èƒ½é–‹å§‹ä»»ä½•ä½¿ç”¨è€…æ•…äº‹å¯¦ä½œ

### è³‡æ–™åº«åŸºç¤

- [X] T006 å»ºç«‹è³‡æ–™åº« schema SQL è…³æœ¬ï¼ˆdata-model.md çš„ 4 å¼µè¡¨ï¼‰
- [X] T007 [P] å¯¦ä½œ ErrorCode Enumï¼ˆexceptions/base.pyï¼Œ16 å€‹éŒ¯èª¤å®šç¾©ï¼‰
- [X] T008 [P] å¯¦ä½œ BaseTransformatExceptionï¼ˆexceptions/base.pyï¼‰
- [X] T009 [P] å¯¦ä½œ SystemException å’Œ ProcessingExceptionï¼ˆexceptions/custom.pyï¼‰

**é©—è­‰**ï¼š
```python
# æ¸¬è©¦ ErrorCode å¯æ­£å¸¸åŒ¯å…¥å’Œä½¿ç”¨
from exceptions.base import ErrorCode
assert ErrorCode.FILE_NOT_FOUND.format(file_path="/test") == "æª”æ¡ˆä¸å­˜åœ¨ï¼š/test"
```

### é…ç½®èˆ‡æ—¥èªŒ

- [X] T010 [P] å¯¦ä½œç’°å¢ƒé…ç½®è®€å–ï¼ˆconfig/settings.pyï¼Œæ”¯æ´ local/ut/uat/prodï¼‰
- [X] T011 [P] å¯¦ä½œ Loguru æ—¥èªŒé…ç½®ï¼ˆutils/logger.pyï¼ŒJSON æ ¼å¼ï¼‰

**é©—è­‰**ï¼š
```python
from config.settings import Settings
from utils.logger import logger
settings = Settings()
logger.info("æ¸¬è©¦è¨Šæ¯")  # æª¢æŸ¥æ—¥èªŒæª”æ¡ˆæ˜¯å¦ç”¢ç”Ÿ
```

### è³‡æ–™åº«é€£ç·š

- [X] T012 å¯¦ä½œè³‡æ–™åº«é€£ç·šæ± ï¼ˆutils/db_connection.pyï¼ŒThreadedConnectionPool 5-15ï¼‰
- [X] T013 æ¸¬è©¦é€£ç·šæ± åŸºæœ¬åŠŸèƒ½ï¼ˆå–å¾—é€£ç·šã€æ­¸é‚„é€£ç·šã€é€£ç·šæ± è€—ç›¡éŒ¯èª¤ï¼‰

**é©—è­‰**ï¼š
```python
from utils.db_connection import create_connection_pool
pool = create_connection_pool()
conn = pool.getconn()
assert conn is not None
pool.putconn(conn)
pool.closeall()
```

### åŸºç¤ Repository

- [X] T014 [P] å¯¦ä½œ FileRecordRepository åŸºç¤é¡åˆ¥ï¼ˆrepositories/file_record_repo.pyï¼‰
  - insert_file_record()
  - get_file_record_by_name()
  - list_pending_files()

**é©—è­‰**ï¼šåŸ·è¡Œå–®å…ƒæ¸¬è©¦ç¢ºèª CRUD æ“ä½œæ­£å¸¸

- [X] T015 [P] å¯¦ä½œ TaskSequenceRepositoryï¼ˆrepositories/task_sequence_repo.pyï¼‰
  - generate_task_id(date) â†’ transformat_YYYYMMDD0001
  - ä½¿ç”¨ SELECT FOR UPDATE ç¢ºä¿ä¸¦è¡Œå®‰å…¨

**é©—è­‰**ï¼š
```python
# æ¸¬è©¦åºåˆ—ç”Ÿæˆ
repo = TaskSequenceRepository(pool)
task_id1 = repo.generate_task_id("20251206")  # transformat_202512060001
task_id2 = repo.generate_task_id("20251206")  # transformat_202512060002
assert task_id1 != task_id2
```

- [X] T016 [P] å¯¦ä½œ FileTaskRepositoryï¼ˆrepositories/file_task_repo.pyï¼‰
  - create_task(file_record_id, file_name, previous_failed_task_id)
  - update_status(task_id, status, error_message)
  - get_task_by_id(task_id)

**é©—è­‰**ï¼šåŸ·è¡Œå–®å…ƒæ¸¬è©¦ç¢ºèªä»»å‹™å»ºç«‹å’Œç‹€æ…‹æ›´æ–°æ­£å¸¸

**æª¢æŸ¥é»**ï¼šåŸºç¤è¨­æ–½å°±ç·’ï¼Œå¯é–‹å§‹ä½¿ç”¨è€…æ•…äº‹ä¸¦è¡Œé–‹ç™¼

---

## éšæ®µ 3ï¼šä½¿ç”¨è€…æ•…äº‹ 1 - åŸºæœ¬æª”æ¡ˆè®€å–èˆ‡æ ¼å¼è½‰æ›ï¼ˆå„ªå…ˆç´šï¼šP1ï¼‰ğŸ¯ MVP

**ç›®æ¨™**ï¼šå¾ SFTP è®€å–å–®ä¸€ txt æª”æ¡ˆï¼Œæ ¹æ“šå›ºå®šé•·åº¦æˆ–åˆ†éš”ç¬¦è™Ÿè§£æï¼Œå¯«å…¥ Parquet æª”æ¡ˆ

**ç¨ç«‹æ¸¬è©¦æ¨™æº–**ï¼š
- å¯è®€å– SFTP ä¸Šçš„ txt æª”æ¡ˆ
- å¯æ­£ç¢ºåµæ¸¬ big5/utf-8 ç·¨ç¢¼
- å¯æ­£ç¢ºè§£æå›ºå®šé•·åº¦æ ¼å¼ï¼ˆè€ƒæ…®ä¸­æ–‡å­—å…ƒå¯¬åº¦ï¼‰
- å¯æ­£ç¢ºè§£æåˆ†éš”ç¬¦è™Ÿæ ¼å¼
- å¯æˆåŠŸå¯«å…¥ Parquet æª”æ¡ˆ
- éŒ¯èª¤è‡ªå‹•è¨˜éŒ„åˆ° file_tasks.error_message

### å¯¦ä½œ - SFTP è®€å–

- [X] T017 [P] [US1] å¯¦ä½œ SFTP é€£ç·šç®¡ç†ï¼ˆservices/sftp_client.pyï¼‰
  - connect_to_sftp() â†’ SFTPClient
  - æ‹‹å‡º SystemException(ErrorCode.SFTP_AUTH_FAILED)
  - æ‹‹å‡º SystemException(ErrorCode.SFTP_NETWORK_ERROR)

**é©—è­‰**ï¼š
```python
# æ¸¬è©¦é€£ç·šæˆåŠŸ
sftp = connect_to_sftp()
assert sftp is not None
sftp.close()

# æ¸¬è©¦èªè­‰å¤±æ•—éŒ¯èª¤
try:
    connect_to_sftp(wrong_password)
except SystemException as e:
    assert e.error_code == ErrorCode.SFTP_AUTH_FAILED
```

- [X] T018 [P] [US1] å¯¦ä½œ SFTP æª”æ¡ˆè®€å–ï¼ˆservices/sftp_client.pyï¼‰
  - read_file_from_sftp(sftp, file_path, task_id) â†’ bytes
  - æ‹‹å‡º ProcessingException(ErrorCode.FILE_NOT_FOUND)
  - æ‹‹å‡º ProcessingException(ErrorCode.FILE_READ_FAILED)

**é©—è­‰**ï¼š
```python
# æ¸¬è©¦æª”æ¡ˆè®€å–
content = read_file_from_sftp(sftp, "/data/test.txt", "test_task")
assert len(content) > 0

# æ¸¬è©¦æª”æ¡ˆä¸å­˜åœ¨éŒ¯èª¤
try:
    read_file_from_sftp(sftp, "/data/notexist.txt", "test_task")
except ProcessingException as e:
    assert e.error_code == ErrorCode.FILE_NOT_FOUND
```

### å¯¦ä½œ - ç·¨ç¢¼åµæ¸¬

- [X] T019 [US1] å¯¦ä½œç·¨ç¢¼åµæ¸¬å™¨ï¼ˆutils/encoding_detector.pyï¼‰
  - detect_encoding(content: bytes, task_id: str) â†’ str
  - å˜—è©¦é †åºï¼šutf-8 â†’ big5 â†’ gbk
  - æ‹‹å‡º ProcessingException(ErrorCode.ENCODING_DETECTION_FAILED)

**é©—è­‰**ï¼š
```python
# æ¸¬è©¦ UTF-8 æª”æ¡ˆ
utf8_content = "æ¸¬è©¦å…§å®¹".encode('utf-8')
assert detect_encoding(utf8_content, "test") == "utf-8"

# æ¸¬è©¦ BIG5 æª”æ¡ˆ
big5_content = "æ¸¬è©¦å…§å®¹".encode('big5')
assert detect_encoding(big5_content, "test") == "big5"

# æ¸¬è©¦ç„¡æ•ˆç·¨ç¢¼
invalid_content = b'\xff\xfe\xff\xfe'
try:
    detect_encoding(invalid_content, "test")
except ProcessingException as e:
    assert e.error_code == ErrorCode.ENCODING_DETECTION_FAILED
```

### å¯¦ä½œ - è³‡æ–™è§£æ

- [X] T020 [P] [US1] å¯¦ä½œå›ºå®šé•·åº¦è§£æå™¨ï¼ˆservices/parser_service.pyï¼‰
  - parse_fixed_length_line(line: str, field_defs: list, line_num: int, task_id: str) â†’ dict
  - ä½¿ç”¨ wcwidth è¨ˆç®—ä¸­æ–‡å­—å…ƒå¯¬åº¦
  - è‡ªå‹• strip() ç§»é™¤ç©ºç™½
  - æ‹‹å‡º ProcessingException(ErrorCode.PARSE_FIXED_LENGTH_FAILED)

**é©—è­‰**ï¼š
```python
# æ¸¬è©¦å›ºå®šé•·åº¦è§£æï¼ˆå…¨å½¢ä¸­æ–‡ï¼‰
field_defs = [{'name': 'col1', 'length': 10}, {'name': 'col2', 'length': 5}]
line = "æ¸¬è©¦      12345"  # æ¸¬è©¦=4å¯¬åº¦, 6ç©ºæ ¼, 12345=5å¯¬åº¦
result = parse_fixed_length_line(line, field_defs, 1, "test")
assert result['col1'] == "æ¸¬è©¦"
assert result['col2'] == "12345"

# æ¸¬è©¦é•·åº¦ä¸ç¬¦éŒ¯èª¤
wrong_line = "çŸ­"
try:
    parse_fixed_length_line(wrong_line, field_defs, 1, "test")
except ProcessingException as e:
    assert e.error_code == ErrorCode.PARSE_FIXED_LENGTH_FAILED
    assert "é æœŸ 15" in e.message
```

- [X] T021 [P] [US1] å¯¦ä½œåˆ†éš”ç¬¦è™Ÿè§£æå™¨ï¼ˆservices/parser_service.pyï¼‰
  - parse_delimiter_line(line: str, delimiter: str, line_num: int, task_id: str) â†’ list
  - æ‹‹å‡º ProcessingException(ErrorCode.PARSE_DELIMITER_FAILED)

**é©—è­‰**ï¼š
```python
# æ¸¬è©¦åˆ†éš”ç¬¦è™Ÿè§£æ
line = "AAA||BBB||CCC"
result = parse_delimiter_line(line, "||", 1, "test")
assert result == ["AAA", "BBB", "CCC"]

# æ¸¬è©¦æ‰¾ä¸åˆ°åˆ†éš”ç¬¦è™ŸéŒ¯èª¤
line_no_delim = "AAABBBCCC"
try:
    parse_delimiter_line(line_no_delim, "||", 1, "test")
except ProcessingException as e:
    assert e.error_code == ErrorCode.PARSE_DELIMITER_FAILED
```

- [X] T022 [US1] å¯¦ä½œæ‰¹æ¬¡è§£æå™¨ï¼ˆservices/parser_service.pyï¼‰
  - parse_file_content(content: str, file_record: FileRecord, task_id: str) â†’ Iterator[dict]
  - æ ¹æ“š file_record.delimiter åˆ¤æ–·è§£ææ–¹å¼
  - ä½¿ç”¨ yield è¿”å›æ‰¹æ¬¡ï¼ˆ30,000 è¡Œ/æ‰¹ï¼‰
  - åœ¨éŒ¯èª¤è¨Šæ¯ä¸­åŒ…å«è¡Œè™Ÿ

**é©—è­‰**ï¼š
```python
# æ¸¬è©¦æ‰¹æ¬¡è§£æï¼ˆå›ºå®šé•·åº¦ï¼‰
content = "æ¸¬è©¦  12345\næ¸¬è©¦  67890\n"
file_record = FileRecord(delimiter=None, field_definitions=[...])
batches = list(parse_file_content(content, file_record, "test"))
assert len(batches) > 0
assert all('col1' in record for batch in batches for record in batch)
```

### å¯¦ä½œ - Parquet å¯«å…¥

- [X] T023 [US1] å¯¦ä½œ Parquet å¯«å…¥å™¨ï¼ˆservices/parquet_writer.pyï¼‰
  - write_parquet(records: Iterator[dict], output_path: str, schema: list, task_id: str) â†’ None
  - ä½¿ç”¨ pyarrow.parquet.ParquetWriter ä¸²æµå¯«å…¥
  - æ¯ 30,000 ç­†å¯«å…¥ä¸€æ¬¡
  - æ‹‹å‡º ProcessingException(ErrorCode.PARQUET_WRITE_FAILED)
  - æ‹‹å‡º ProcessingException(ErrorCode.PARQUET_DISK_SPACE_INSUFFICIENT)

**é©—è­‰**ï¼š
```python
# æ¸¬è©¦ Parquet å¯«å…¥
records = [{'col1': 'æ¸¬è©¦', 'col2': '12345'} for _ in range(100)]
schema = [{'name': 'col1', 'type': 'string'}, {'name': 'col2', 'type': 'string'}]
output_path = "/tmp/test_output.parquet"
write_parquet(iter(records), output_path, schema, "test")
assert os.path.exists(output_path)

# é©—è­‰å¯è®€å–
import pyarrow.parquet as pq
table = pq.read_table(output_path)
assert len(table) == 100
```

### æ•´åˆ - æª”æ¡ˆè™•ç†ä¸»æµç¨‹

- [X] T024 [US1] å¯¦ä½œæª”æ¡ˆè™•ç†æœå‹™ï¼ˆservices/file_processor.pyï¼‰
  - process_file(task_id: str) â†’ None
  - æ•´åˆï¼šSFTP è®€å– â†’ ç·¨ç¢¼åµæ¸¬ â†’ è§£æ â†’ Parquet å¯«å…¥
  - çµ±ä¸€éŒ¯èª¤è™•ç†ï¼ˆSystemException / ProcessingExceptionï¼‰
  - è‡ªå‹•è¨˜éŒ„éŒ¯èª¤åˆ° file_tasks.error_message

**é©—è­‰**ï¼š
```python
# æº–å‚™æ¸¬è©¦è³‡æ–™
task_repo.create_task(file_record_id=1, file_name="test.txt", previous_failed_task_id=None)
task_id = "transformat_202512060001"

# åŸ·è¡Œè™•ç†
process_file(task_id)

# é©—è­‰çµæœ
task = task_repo.get_task_by_id(task_id)
assert task['status'] == 'completed'
assert os.path.exists(output_path)
```

**æª¢æŸ¥é»**ï¼šæ­¤æ™‚ US1 å®Œæ•´åŠŸèƒ½ï¼Œå¯è™•ç†å–®ä¸€æª”æ¡ˆä¸¦é©—è­‰çµæœ

---

## éšæ®µ 4ï¼šä½¿ç”¨è€…æ•…äº‹ 2 - å¤šæª”æ¡ˆæ‰¹æ¬¡è™•ç†èˆ‡ä¸¦è¡Œæ§åˆ¶ï¼ˆå„ªå…ˆç´šï¼šP1ï¼‰

**ç›®æ¨™**ï¼šä¸€æ¬¡è®€å–è³‡æ–™åº«æ‰€æœ‰å¾…è™•ç†æª”æ¡ˆï¼Œä½¿ç”¨ Advisory Lock é¿å…å¤š Pod ç«¶çˆ­

**ç¨ç«‹æ¸¬è©¦æ¨™æº–**ï¼š
- å¯å¾è³‡æ–™åº«è®€å–æ‰€æœ‰å¾…è™•ç†æª”æ¡ˆæ¸…å–®
- å¯ä½¿ç”¨ Advisory Lock é–å®šä»»å‹™
- å¤šå€‹ç¨‹åºåŒæ™‚åŸ·è¡Œæ™‚ä¸æœƒè™•ç†åŒä¸€æª”æ¡ˆ
- è™•ç†å®Œæˆå¾Œè‡ªå‹•é‡‹æ”¾é–
- éŒ¯èª¤æª”æ¡ˆä¸å½±éŸ¿å…¶ä»–æª”æ¡ˆè™•ç†

### å¯¦ä½œ - Advisory Lock ç®¡ç†

- [X] T025 [P] [US2] å¯¦ä½œ Advisory Lock ç®¡ç†å™¨ï¼ˆservices/lock_manager.pyï¼‰
  - try_acquire_lock(task_id: str, conn) â†’ bool
  - release_lock(task_id: str, conn) â†’ None
  - ä½¿ç”¨ pg_try_advisory_lock(hashtext(task_id))
  - æ‹‹å‡º SystemException(ErrorCode.ADVISORY_LOCK_FAILED)

**é©—è­‰**ï¼š
```python
# æ¸¬è©¦é–å–å¾—
conn1 = pool.getconn()
lock_mgr = LockManager()
assert lock_mgr.try_acquire_lock("test_task", conn1) == True

# æ¸¬è©¦é–ç«¶çˆ­
conn2 = pool.getconn()
assert lock_mgr.try_acquire_lock("test_task", conn2) == False

# æ¸¬è©¦é–é‡‹æ”¾
lock_mgr.release_lock("test_task", conn1)
assert lock_mgr.try_acquire_lock("test_task", conn2) == True
```

### å¯¦ä½œ - æ‰¹æ¬¡è™•ç†ä¸»æµç¨‹

- [X] T026 [US2] æ“´å±• FileTaskRepository æ‰¹æ¬¡æ–¹æ³•
  - list_pending_tasks(limit: int) â†’ List[dict]
  - æŸ¥è©¢ status='pending' çš„ä»»å‹™

**é©—è­‰**ï¼š
```python
# å»ºç«‹æ¸¬è©¦ä»»å‹™
for i in range(5):
    task_repo.create_task(file_record_id=i, file_name=f"file{i}.txt", previous_failed_task_id=None)

# æŸ¥è©¢å¾…è™•ç†ä»»å‹™
tasks = task_repo.list_pending_tasks(limit=10)
assert len(tasks) == 5
assert all(t['status'] == 'pending' for t in tasks)
```

- [X] T027 [US2] å¯¦ä½œæ‰¹æ¬¡è™•ç†ä¸»ç¨‹å¼ï¼ˆmain.pyï¼‰
  - process_pending_tasks(db_pool, sftp_client) â†’ None
  - è®€å–æ‰€æœ‰ pending ä»»å‹™
  - é€ä¸€å˜—è©¦å–å¾— Advisory Lock
  - æˆåŠŸå–å¾—é– â†’ å‘¼å« process_file()
  - å¤±æ•—å–å¾—é– â†’ è·³éè©²ä»»å‹™
  - ä½¿ç”¨ try-finally ç¢ºä¿é–é‡‹æ”¾

**é©—è­‰**ï¼š
```python
# å»ºç«‹ 5 å€‹å¾…è™•ç†ä»»å‹™
# ...

# åŸ·è¡Œæ‰¹æ¬¡è™•ç†
process_pending_tasks(db_pool, sftp_client)

# é©—è­‰çµæœ
completed_tasks = task_repo.list_tasks_by_status('completed')
assert len(completed_tasks) == 5
```

### å¯¦ä½œ - å•Ÿå‹•éšæ®µéŒ¯èª¤è™•ç†

- [X] T028 [US2] å¯¦ä½œæ‡‰ç”¨ç¨‹å¼å…¥å£é»ï¼ˆmain.pyï¼‰
  - main() å‡½æ•¸
  - å•Ÿå‹•éšæ®µéŒ¯èª¤è™•ç†ï¼ˆSystemException â†’ exit 1ï¼‰
  - è³‡æºæ¸…ç†ï¼ˆfinally å€å¡Šï¼‰

**é©—è­‰**ï¼š
```bash
# æ¸¬è©¦æ­£å¸¸å•Ÿå‹•
python src/transformat/main.py
# æ‡‰è©²çœ‹åˆ°æ—¥èªŒï¼šæ­£åœ¨å»ºç«‹è³‡æ–™åº«é€£ç·šæ± ...

# æ¸¬è©¦å•Ÿå‹•å¤±æ•—ï¼ˆéŒ¯èª¤çš„è³‡æ–™åº«è¨­å®šï¼‰
# æ‡‰è©²çœ‹åˆ° CRITICAL æ—¥èªŒä¸¦ exit 1
```

**æª¢æŸ¥é»**ï¼šæ­¤æ™‚ US2 å®Œæ•´åŠŸèƒ½ï¼Œå¯æ‰¹æ¬¡è™•ç†å¤šå€‹æª”æ¡ˆä¸”é¿å…ç«¶çˆ­

---

## éšæ®µ 5ï¼šä½¿ç”¨è€…æ•…äº‹ 3 - å‘¼å«é®ç½©è½‰æ›æœå‹™èˆ‡é‡è©¦æ©Ÿåˆ¶ï¼ˆå„ªå…ˆç´šï¼šP2ï¼‰

**ç›®æ¨™**ï¼šè™•ç†å®Œæˆå¾Œå‘¼å«ä¸‹æ¸¸é®ç½©æœå‹™ï¼Œå¤±æ•—æ™‚æœ€å¤šé‡è©¦ 3 æ¬¡

**ç¨ç«‹æ¸¬è©¦æ¨™æº–**ï¼š
- å¯æˆåŠŸå‘¼å«ä¸‹æ¸¸ API
- 5xx éŒ¯èª¤è‡ªå‹•é‡è©¦ï¼ˆæœ€å¤š 3 æ¬¡ï¼ŒæŒ‡æ•¸é€€é¿ï¼‰
- 4xx éŒ¯èª¤ä¸é‡è©¦
- é‡è©¦å¤±æ•—å¾Œæ¨™è¨˜ä»»å‹™å¤±æ•—
- éŒ¯èª¤è¨Šæ¯åŒ…å« HTTP ç‹€æ…‹ç¢¼å’ŒåŸå› 

### å¯¦ä½œ - ä¸‹æ¸¸ API å‘¼å«

- [X] T029 [P] [US3] å¯¦ä½œä¸‹æ¸¸ API å‘¼å«å™¨ï¼ˆservices/downstream_caller.pyï¼‰
  - call_mask_api(task_id: str, parquet_path: str) â†’ dict
  - ä½¿ç”¨ requests + tenacity é‡è©¦è£é£¾å™¨
  - é‡è©¦ç­–ç•¥ï¼š3 æ¬¡ï¼ŒæŒ‡æ•¸é€€é¿ 1-10 ç§’
  - 5xx éŒ¯èª¤å¯é‡è©¦
  - 4xx éŒ¯èª¤ä¸é‡è©¦
  - æ‹‹å‡º SystemException(ErrorCode.DOWNSTREAM_CONNECTION_FAILED)
  - æ‹‹å‡º ProcessingException(ErrorCode.DOWNSTREAM_API_ERROR)

**é©—è­‰**ï¼š
```python
# æ¸¬è©¦æˆåŠŸå‘¼å«ï¼ˆä½¿ç”¨ mock æˆ–æ¸¬è©¦ç’°å¢ƒï¼‰
response = call_mask_api("test_task", "/output/test.parquet")
assert response['status'] == 'success'

# æ¸¬è©¦ 5xx éŒ¯èª¤é‡è©¦
# Mock API è¿”å› 503 å…©æ¬¡ï¼Œç¬¬ä¸‰æ¬¡è¿”å› 200
# é©—è­‰é‡è©¦æ¬¡æ•¸ = 2

# æ¸¬è©¦ 4xx éŒ¯èª¤ä¸é‡è©¦
# Mock API è¿”å› 400
try:
    call_mask_api("test_task", "/output/test.parquet")
except ProcessingException as e:
    assert e.error_code == ErrorCode.DOWNSTREAM_API_ERROR
    assert "400" in e.message
```

### æ•´åˆ - åŠ å…¥ä¸‹æ¸¸ API å‘¼å«

- [X] T030 [US3] æ“´å±• process_file() åŠ å…¥ä¸‹æ¸¸ API å‘¼å«
  - åœ¨ Parquet å¯«å…¥æˆåŠŸå¾Œå‘¼å« call_mask_api()
  - æ•æ‰ API éŒ¯èª¤ä¸¦è¨˜éŒ„åˆ° file_tasks.error_message

**é©—è­‰**ï¼š
```python
# åŸ·è¡Œæª”æ¡ˆè™•ç†
process_file(task_id)

# é©—è­‰ API å·²è¢«å‘¼å«ï¼ˆæª¢æŸ¥ mock æˆ–æ—¥èªŒï¼‰
# é©—è­‰ä»»å‹™ç‹€æ…‹ = completed
```

**æª¢æŸ¥é»**ï¼šæ­¤æ™‚ US3 å®Œæ•´åŠŸèƒ½ï¼Œå¯å‘¼å«ä¸‹æ¸¸æœå‹™ä¸¦è™•ç†é‡è©¦

---

## éšæ®µ 6ï¼šä½¿ç”¨è€…æ•…äº‹ 4 - è³‡æ–™é¡å‹è™•ç†èˆ‡æ¬„ä½è½‰ç¢¼æ¨™è¨˜ï¼ˆå„ªå…ˆç´šï¼šP3ï¼‰

**ç›®æ¨™**ï¼šæ ¹æ“š field_definitions çš„ data_type å’Œ transform_type è™•ç†æ¬„ä½

**ç¨ç«‹æ¸¬è©¦æ¨™æº–**ï¼š
- å¯æ­£ç¢ºè½‰æ›è³‡æ–™é¡å‹ï¼ˆstring, int, double, timestampï¼‰
- ä¿ç•™ transform_type æ¨™è¨˜åˆ° Parquet metadata
- é¡å‹è½‰æ›å¤±æ•—æ™‚è¨˜éŒ„éŒ¯èª¤ä½†ç¹¼çºŒè™•ç†

### å¯¦ä½œ - è³‡æ–™é¡å‹è½‰æ›

- [X] T031 [P] [US4] å¯¦ä½œè³‡æ–™é¡å‹è½‰æ›å™¨ï¼ˆutils/type_converter.pyï¼‰
  - convert_value(value: str, data_type: str, field_name: str) â†’ Any
  - æ”¯æ´é¡å‹ï¼šstring, int, double, timestamp
  - timestamp æ ¼å¼ï¼šYYYY-MM-DD HH:MM:SS
  - è½‰æ›å¤±æ•—è¿”å› None ä¸¦è¨˜éŒ„è­¦å‘Š

**é©—è­‰**ï¼š
```python
# æ¸¬è©¦ int è½‰æ›
assert convert_value("12345", "int", "col1") == 12345
assert convert_value("abc", "int", "col1") is None  # è½‰æ›å¤±æ•—

# æ¸¬è©¦ double è½‰æ›
assert convert_value("123.45", "double", "col2") == 123.45

# æ¸¬è©¦ timestamp è½‰æ›
from datetime import datetime
result = convert_value("2025-12-06 10:00:00", "timestamp", "col3")
assert isinstance(result, datetime)

# æ¸¬è©¦ stringï¼ˆä¿æŒåŸæ¨£ï¼‰
assert convert_value("æ¸¬è©¦", "string", "col4") == "æ¸¬è©¦"
```

### æ•´åˆ - åŠ å…¥é¡å‹è½‰æ›

- [X] T032 [US4] æ“´å±• parse_file_content() åŠ å…¥é¡å‹è½‰æ›
  - åœ¨è§£æå¾Œç«‹å³è½‰æ›æ¯å€‹æ¬„ä½çš„è³‡æ–™é¡å‹
  - è½‰æ›å¤±æ•—è¨˜éŒ„è­¦å‘Šä½†ä¸ä¸­æ–·è™•ç†

**é©—è­‰**ï¼š
```python
# æº–å‚™æ¸¬è©¦è³‡æ–™ï¼ˆåŒ…å«ä¸åŒé¡å‹ï¼‰
field_defs = [
    {'name': 'id', 'type': 'int'},
    {'name': 'amount', 'type': 'double'},
    {'name': 'date', 'type': 'timestamp'},
    {'name': 'name', 'type': 'string'}
]
content = "00001||123.45||2025-12-06 10:00:00||æ¸¬è©¦\n"
file_record = FileRecord(delimiter="||", field_definitions=field_defs)

batches = list(parse_file_content(content, file_record, "test"))
record = batches[0][0]

assert isinstance(record['id'], int)
assert isinstance(record['amount'], float)
assert isinstance(record['date'], datetime)
assert isinstance(record['name'], str)
```

- [X] T033 [US4] æ“´å±• write_parquet() åŠ å…¥ transform_type metadata
  - å°‡ transform_type å¯«å…¥ Parquet schema metadata
  - ä¸‹æ¸¸æœå‹™å¯è®€å– metadata äº†è§£è½‰ç¢¼éœ€æ±‚

**é©—è­‰**ï¼š
```python
# å¯«å…¥ Parquet å« transform_type
field_defs = [
    {'name': 'id', 'type': 'int', 'transform_type': 'mask'},
    {'name': 'name', 'type': 'string', 'transform_type': 'hash'}
]
write_parquet(records, output_path, field_defs, "test")

# è®€å–é©—è­‰ metadata
import pyarrow.parquet as pq
parquet_file = pq.ParquetFile(output_path)
metadata = parquet_file.schema_arrow.metadata
assert b'transform_type' in metadata
```

**æª¢æŸ¥é»**ï¼šæ­¤æ™‚ US4 å®Œæ•´åŠŸèƒ½ï¼Œå¯è™•ç†è³‡æ–™é¡å‹ä¸¦æ¨™è¨˜è½‰ç¢¼éœ€æ±‚

---

## éšæ®µ 7ï¼šPolish & è·¨åˆ‡é¢é—œæ³¨é»

**ç›®çš„**ï¼šæœ€çµ‚å„ªåŒ–å’Œç”Ÿç”¢ç’°å¢ƒæº–å‚™

### ä»»å‹™ç‹€æ…‹ä¸ä¸€è‡´ä¿®å¾©

- [X] T034 [P] å¯¦ä½œå•Ÿå‹•æ™‚çš„ç‹€æ…‹ä¿®å¾©ï¼ˆmain.pyï¼‰
  - æƒææ‰€æœ‰ status='processing' ä¸”è¶…é 1 å°æ™‚çš„ä»»å‹™
  - é‡ç½®ç‚º status='pending'
  - è¨˜éŒ„ä¿®å¾©æ—¥èªŒ

**é©—è­‰**ï¼š
```python
# å»ºç«‹é€¾æ™‚ä»»å‹™ï¼ˆstarted_at = 2 å°æ™‚å‰ï¼Œstatus='processing'ï¼‰
# ...

# åŸ·è¡Œå•Ÿå‹•ä¿®å¾©
fix_inconsistent_tasks(db_pool)

# é©—è­‰ä»»å‹™å·²é‡ç½®ç‚º pending
task = task_repo.get_task_by_id(task_id)
assert task['status'] == 'pending'
```

### å‰æ¬¡å¤±æ•—ä»»å‹™é—œè¯

- [X] T035 å¯¦ä½œå‰æ¬¡å¤±æ•—ä»»å‹™è¿½è¹¤ï¼ˆservices/file_processor.pyï¼‰
  - åœ¨ create_task() æ™‚æŸ¥è©¢åŒåæª”æ¡ˆçš„å‰æ¬¡å¤±æ•—ä»»å‹™
  - è¨­å®š previous_failed_task_id

**é©—è­‰**ï¼š
```python
# å»ºç«‹å¤±æ•—ä»»å‹™
task1 = task_repo.create_task(file_record_id=1, file_name="test.txt", previous_failed_task_id=None)
task_repo.update_status(task1, 'failed', "æ¸¬è©¦éŒ¯èª¤")

# å»ºç«‹é‡è©¦ä»»å‹™
task2 = task_repo.create_task(file_record_id=1, file_name="test.txt", previous_failed_task_id=None)

# é©—è­‰é—œè¯
task2_info = task_repo.get_task_by_id(task2)
assert task2_info['previous_failed_task_id'] == task1
```

### æ•ˆèƒ½å„ªåŒ–

- [ ] T036 [P] é©—è­‰ä¸²æµè™•ç†æ•ˆèƒ½ï¼ˆæ¸¬è©¦ 1GB æª”æ¡ˆï¼‰
  - è¨˜æ†¶é«”ä½¿ç”¨é‡ < 500MB
  - è™•ç†é€Ÿåº¦ > 10,000 rows/sec

- [ ] T037 [P] é©—è­‰é€£ç·šæ± è¡Œç‚ºï¼ˆä¸¦è¡Œæ¸¬è©¦ï¼‰
  - åŒæ™‚åŸ·è¡Œ 20 å€‹ä»»å‹™
  - é€£ç·šæ± ä¸è€—ç›¡
  - ç„¡é€£ç·šæ´©æ¼

### æ–‡ä»¶èˆ‡éƒ¨ç½²

- [X] T038 [P] å»ºç«‹ README.mdï¼ˆå®‰è£ã€é…ç½®ã€åŸ·è¡Œèªªæ˜ï¼‰
- [X] T039 [P] å»ºç«‹ Kubernetes CronJob YAMLï¼ˆä¾ç…§ plan.md Â§éƒ¨ç½²æ¶æ§‹ï¼‰
- [X] T040 [P] å»ºç«‹å‡è³‡æ–™ SQL è…³æœ¬ï¼ˆquickstart.md çš„ç¯„ä¾‹è³‡æ–™ï¼‰

**æª¢æŸ¥é»**ï¼šå°ˆæ¡ˆå®Œæ•´ï¼Œå¯éƒ¨ç½²è‡³ç”Ÿç”¢ç’°å¢ƒ

---

## ä¾è³´é—œä¿‚èˆ‡åŸ·è¡Œé †åº

### å¿…é ˆé †åºåŸ·è¡Œ

1. **éšæ®µ 1** â†’ **éšæ®µ 2**ï¼šåŸºç¤è¨­æ–½å¿…é ˆå…ˆå®Œæˆ
2. **éšæ®µ 2** â†’ **éšæ®µ 3/4/5/6**ï¼šåŸºç¤è¨­æ–½å®Œæˆå¾Œæ‰èƒ½é–‹å§‹ä½¿ç”¨è€…æ•…äº‹
3. **éšæ®µ 3** â†’ **éšæ®µ 5**ï¼šUS1 å®Œæˆå¾Œæ‰èƒ½åŠ å…¥ä¸‹æ¸¸ APIï¼ˆUS3ï¼‰

### å¯ä¸¦è¡ŒåŸ·è¡Œ

- **éšæ®µ 3 (US1)** âˆ¥ **éšæ®µ 4 (US2)**ï¼šæª”æ¡ˆè™•ç†é‚è¼¯èˆ‡æ‰¹æ¬¡è™•ç†é‚è¼¯å¯åˆ†é–‹é–‹ç™¼
- **éšæ®µ 6 (US4)**ï¼šå¯åœ¨ US1 å®Œæˆå¾Œéš¨æ™‚åŠ å…¥ï¼Œä¸é˜»å¡å…¶ä»–åŠŸèƒ½
- æ¨™è¨˜ `[P]` çš„ä»»å‹™ï¼šå¯èˆ‡å…¶ä»– `[P]` ä»»å‹™ä¸¦è¡ŒåŸ·è¡Œ

### ä½¿ç”¨è€…æ•…äº‹å®Œæˆé †åº

```
éšæ®µ 1 (è¨­å®š)
    â†“
éšæ®µ 2 (åŸºç¤è¨­æ–½) â† å¿…é ˆå®Œæˆ
    â†“
    â”œâ”€â”€â†’ éšæ®µ 3 (US1 - åŸºæœ¬æª”æ¡ˆè™•ç†) ğŸ¯ MVP
    â”‚        â†“
    â”‚    éšæ®µ 5 (US3 - ä¸‹æ¸¸ API)
    â”‚
    â”œâ”€â”€â†’ éšæ®µ 4 (US2 - æ‰¹æ¬¡è™•ç†)
    â”‚
    â””â”€â”€â†’ éšæ®µ 6 (US4 - è³‡æ–™é¡å‹)
         â†“
éšæ®µ 7 (Polish)
```

---

## ä¸¦è¡ŒåŸ·è¡Œç¯„ä¾‹ï¼šä½¿ç”¨è€…æ•…äº‹ 1

**é–‹ç™¼è€… A**ï¼š
```bash
# SFTP + ç·¨ç¢¼åµæ¸¬
T017: å¯¦ä½œ SFTP é€£ç·šç®¡ç†
T018: å¯¦ä½œ SFTP æª”æ¡ˆè®€å–
T019: å¯¦ä½œç·¨ç¢¼åµæ¸¬å™¨
```

**é–‹ç™¼è€… B**ï¼ˆåŒæ™‚é€²è¡Œï¼‰ï¼š
```bash
# è³‡æ–™è§£æ
T020: å¯¦ä½œå›ºå®šé•·åº¦è§£æå™¨
T021: å¯¦ä½œåˆ†éš”ç¬¦è™Ÿè§£æå™¨
T022: å¯¦ä½œæ‰¹æ¬¡è§£æå™¨
```

**é–‹ç™¼è€… C**ï¼ˆåŒæ™‚é€²è¡Œï¼‰ï¼š
```bash
# Parquet å¯«å…¥
T023: å¯¦ä½œ Parquet å¯«å…¥å™¨
```

**æ•´åˆ**ï¼š
```bash
T024: å¯¦ä½œæª”æ¡ˆè™•ç†æœå‹™ï¼ˆæ•´åˆ A+B+Cï¼‰
```

---

## å¯¦ä½œç­–ç•¥

### MVP å„ªå…ˆï¼ˆå»ºè­°å…ˆå®Œæˆï¼‰

**æœ€å°å¯è¡Œç”¢å“ = éšæ®µ 1 + éšæ®µ 2 + éšæ®µ 3 (US1)**

- å¯è™•ç†å–®ä¸€æª”æ¡ˆ
- æ”¯æ´å›ºå®šé•·åº¦å’Œåˆ†éš”ç¬¦è™Ÿæ ¼å¼
- è‡ªå‹•éŒ¯èª¤è™•ç†å’Œè¨˜éŒ„
- **é è¨ˆé–‹ç™¼æ™‚é–“**ï¼š3-5 å¤©

### æ¼¸é€²å¼äº¤ä»˜

1. **ç¬¬ä¸€æ¬¡äº¤ä»˜**ï¼šMVPï¼ˆUS1ï¼‰
2. **ç¬¬äºŒæ¬¡äº¤ä»˜**ï¼š+ US2ï¼ˆæ‰¹æ¬¡è™•ç†ï¼‰
3. **ç¬¬ä¸‰æ¬¡äº¤ä»˜**ï¼š+ US3ï¼ˆä¸‹æ¸¸ APIï¼‰
4. **ç¬¬å››æ¬¡äº¤ä»˜**ï¼š+ US4ï¼ˆè³‡æ–™é¡å‹ï¼‰+ Polish

---

## é©—è­‰æª¢æŸ¥æ¸…å–®

æ¯å€‹ä»»å‹™å®Œæˆå¾Œå¿…é ˆé©—è­‰ï¼š

**ç¨‹å¼ç¢¼å“è³ª**ï¼š
- [ ] éµå¾ª PEP 8 é¢¨æ ¼è¦ç¯„
- [ ] æ‰€æœ‰å‡½æ•¸éƒ½æœ‰ docstringï¼ˆç¹é«”ä¸­æ–‡ï¼‰
- [ ] éŒ¯èª¤è¨Šæ¯ä½¿ç”¨ç¹é«”ä¸­æ–‡
- [ ] ä½¿ç”¨ ErrorCode çµ±ä¸€ç®¡ç†éŒ¯èª¤

**åŠŸèƒ½é©—è­‰**ï¼š
- [ ] å–®å…ƒæ¸¬è©¦é€šéï¼ˆå¦‚æœæœ‰ï¼‰
- [ ] æ‰‹å‹•æ¸¬è©¦é©—è­‰é€šé
- [ ] éŒ¯èª¤å ´æ™¯æ¸¬è©¦é€šé
- [ ] æ—¥èªŒè¼¸å‡ºæ­£ç¢ºï¼ˆJSON æ ¼å¼ï¼‰

**æ•´åˆé©—è­‰**ï¼š
- [ ] å¯èˆ‡å…¶ä»–æ¨¡çµ„æ­£ç¢ºæ•´åˆ
- [ ] è³‡æ–™åº«æ“ä½œæ­£ç¢ºï¼ˆç„¡éºæ¼çš„é€£ç·šï¼‰
- [ ] ç•°å¸¸è™•ç†æ­£ç¢ºï¼ˆSystemException / ProcessingExceptionï¼‰

---

## æ³¨æ„äº‹é …

1. **ä»»å‹™å¤§å°**ï¼šæ¯å€‹ä»»å‹™æ‡‰åœ¨ 30 åˆ†é˜å…§å®Œæˆï¼Œç«‹å³å¯é©—è­‰çµæœ
2. **ç¨ç«‹æ€§**ï¼šæ¨™è¨˜ `[P]` çš„ä»»å‹™å¯ä¸¦è¡Œé–‹ç™¼ï¼Œä¸æœƒæœ‰æª”æ¡ˆè¡çª
3. **é©—è­‰å„ªå…ˆ**ï¼šæ¯å€‹ä»»å‹™å®Œæˆå¾Œç«‹å³åŸ·è¡Œé©—è­‰è…³æœ¬
4. **éŒ¯èª¤è™•ç†**ï¼šæ‰€æœ‰å¤–éƒ¨å‘¼å«å¿…é ˆä½¿ç”¨ ErrorCode
5. **æ—¥èªŒè¨˜éŒ„**ï¼šæ‰€æœ‰é—œéµæ“ä½œå¿…é ˆè¨˜éŒ„æ—¥èªŒï¼ˆINFO/ERROR ç´šåˆ¥ï¼‰
6. **æ¸¬è©¦è³‡æ–™**ï¼šä½¿ç”¨ quickstart.md æä¾›çš„å‡è³‡æ–™é€²è¡Œæ¸¬è©¦
7. **æäº¤é »ç‡**ï¼šæ¯å®Œæˆä¸€å€‹ä»»å‹™å³æäº¤ï¼Œä¿æŒå°æ­¥æäº¤

---

**ç¸½ä»»å‹™æ•¸**ï¼š40 å€‹ä»»å‹™
**é è¨ˆé–‹ç™¼æ™‚é–“**ï¼š
- MVPï¼ˆUS1ï¼‰ï¼š3-5 å¤©
- å®Œæ•´åŠŸèƒ½ï¼š10-15 å¤©

**ä¸¦è¡Œæ©Ÿæœƒ**ï¼š20+ å€‹ä»»å‹™å¯ä¸¦è¡ŒåŸ·è¡Œ
